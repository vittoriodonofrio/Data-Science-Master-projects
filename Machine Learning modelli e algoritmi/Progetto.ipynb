{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "97068328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import log_loss, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, ComplementNB\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c902fb5",
   "metadata": {},
   "source": [
    "# Costruzione del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "57d03604",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv(\"C:/Users/Vittorio D'Onofrio/Downloads/credit_record.csv\" , sep=',' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b32681cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "application = pd.read_csv ( \"C:/Users/Vittorio D'Onofrio/Downloads/application_record.csv\" , sep=',' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf408af5",
   "metadata": {},
   "source": [
    "L'idea è quella di impostare un problema di classificazione binario, in cui la colonna target vale 1 se il cliente è un cattivo pagatore e 0 altrimenti.\\\n",
    "La tabella credit contiene lo storico dei pagamenti dei clienti a cui è stata data la carta ed è da qui che possiamo dedurre (o meglio ipotizzare) che un determinato id sia o meno un cattivo pagatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3405701a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001711</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5001711</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5001711</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5001711</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5001712</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  MONTHS_BALANCE STATUS\n",
       "0  5001711               0      X\n",
       "1  5001711              -1      0\n",
       "2  5001711              -2      0\n",
       "3  5001711              -3      0\n",
       "4  5001712               0      C"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d16c625",
   "metadata": {},
   "source": [
    "Il criterio scelto per vedere se un cliente è un cattivo pagatore o meno è il seguente: se la media dei suoi ritardi nei pagamenti supera 59 giorni allora è un cattivo pagatore.\\\n",
    "La media sembra essere la statistica migliore per questo problema perchè è sensibile agli outliers e quindi anche solo un ritardo di più di 150 giorni può influire nella valutazione del cliente e questo sembra avere senso.\\\n",
    "In generale non c'è un modo univoco per identificare un cattivo pagatore ed il criterio dovrebbe essere scelto anche in accordo con le linee guida dell'istituto per cui si svolge questo progetto.\\\n",
    "Infatti, la banca potrebbe decidere di prendersi meno rischio e classificare come cattivo pagatore ad esempio uno che ha una media di ritardi nei pagamenti anche al di sotto di due mesi, oppure di classificare a priori come cattivo pagatore uno che ha avuto almeno una volta più di 150 giorni di ritardo.\\\n",
    "Viceversa, la banca può decidere di assumere più rischio e alzare la soglia della media per la classificazione: si potrebbe ad esempio stabilire che un cliente è un cattivo pagatore quando la media dei suoi ritardi nei pagamenti supera ad esempio 119 giorni."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acfa539",
   "metadata": {},
   "source": [
    "Con la cella seguente creo un dataframe \"credit_new\" in cui un cliente è classificato come cattivo pagatore quando la media dei ritardi nei pagamenti supera 59 giorni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b934996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_new = pd.DataFrame(columns=['ID', 'IS_BAD_PAYER'])\n",
    "\n",
    "for id in set(credit['ID']):\n",
    "    \n",
    "    delay_list = []\n",
    "    df = credit[credit['ID'] == id]\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        selected = row['STATUS']\n",
    "        if selected == 'X' or selected =='C':\n",
    "            df.at[index,'STATUS'] = 0\n",
    "        else:\n",
    "            df.at[index,'STATUS'] = int(selected) + 1\n",
    "        \n",
    "        num_value = df.at[index,'STATUS']\n",
    "    \n",
    "        if num_value > 0:\n",
    "            delay_list.append(num_value)\n",
    "        \n",
    "    if len(delay_list)==0:\n",
    "        flag_bad_payer = 0\n",
    "    else:\n",
    "        mean_delay = sum(delay_list)/len(delay_list)\n",
    "        if mean_delay > 2:\n",
    "            flag_bad_payer = 1\n",
    "        else:\n",
    "            flag_bad_payer = 0\n",
    "        \n",
    "    new_row = {'ID': id , 'IS_BAD_PAYER': flag_bad_payer }   \n",
    "    credit_new = pd.concat([credit_new, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d9620ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>IS_BAD_PAYER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>5113621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>5113920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>5113933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>5113944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>5114236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44948</th>\n",
       "      <td>5105045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44956</th>\n",
       "      <td>5105056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45164</th>\n",
       "      <td>5105325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45554</th>\n",
       "      <td>5105788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45785</th>\n",
       "      <td>5106077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID IS_BAD_PAYER\n",
       "786    5113621            1\n",
       "1014   5113920            1\n",
       "1025   5113933            1\n",
       "1032   5113944            1\n",
       "1268   5114236            1\n",
       "...        ...          ...\n",
       "44948  5105045            1\n",
       "44956  5105056            1\n",
       "45164  5105325            1\n",
       "45554  5105788            1\n",
       "45785  5106077            1\n",
       "\n",
       "[211 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_new[credit_new['IS_BAD_PAYER']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c81c32c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    45774\n",
       "1      211\n",
       "Name: IS_BAD_PAYER, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_new['IS_BAD_PAYER'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f4e4e",
   "metadata": {},
   "source": [
    "Creo il dataframe su cui addestrare il modello attraverso una inner join tra la tabella delle applicazioni e la credit_new appena creata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e7c79543",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(application, credit_new, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d887aaf3",
   "metadata": {},
   "source": [
    "Per comodità si può esportare il dataset appena creato in csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "78f73dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "22ee88c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/Vittorio D'Onofrio/Downloads/data.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3fdd01f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>IS_BAD_PAYER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5008804</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4275000</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5008805</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4275000</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5008806</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>1125000</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-21474</td>\n",
       "      <td>-1134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5008808</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2700000</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19110</td>\n",
       "      <td>-3051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5008809</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2700000</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19110</td>\n",
       "      <td>-3051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "0  5008804           M            Y               Y             0   \n",
       "1  5008805           M            Y               Y             0   \n",
       "2  5008806           M            Y               Y             0   \n",
       "3  5008808           F            N               Y             0   \n",
       "4  5008809           F            N               Y             0   \n",
       "\n",
       "   AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
       "0           4275000               Working               Higher education   \n",
       "1           4275000               Working               Higher education   \n",
       "2           1125000               Working  Secondary / secondary special   \n",
       "3           2700000  Commercial associate  Secondary / secondary special   \n",
       "4           2700000  Commercial associate  Secondary / secondary special   \n",
       "\n",
       "     NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "0        Civil marriage   Rented apartment      -12005          -4542   \n",
       "1        Civil marriage   Rented apartment      -12005          -4542   \n",
       "2               Married  House / apartment      -21474          -1134   \n",
       "3  Single / not married  House / apartment      -19110          -3051   \n",
       "4  Single / not married  House / apartment      -19110          -3051   \n",
       "\n",
       "   FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
       "0           1                1           0           0             NaN   \n",
       "1           1                1           0           0             NaN   \n",
       "2           1                0           0           0  Security staff   \n",
       "3           1                0           1           1     Sales staff   \n",
       "4           1                0           1           1     Sales staff   \n",
       "\n",
       "   CNT_FAM_MEMBERS  IS_BAD_PAYER  \n",
       "0               20             0  \n",
       "1               20             0  \n",
       "2               20             0  \n",
       "3               10             0  \n",
       "4               10             0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2d305d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36457, 19)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cb9afb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36261\n",
       "1      196\n",
       "Name: IS_BAD_PAYER, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['IS_BAD_PAYER'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d5b05",
   "metadata": {},
   "source": [
    "Il problema di classificazione è chiaramente sbilanciato, ha senso visto che ci si aspetta che tra i clienti di una banca ci siano pochi cattivi pagatori e moltissimi buoni pagatori."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3cabb9",
   "metadata": {},
   "source": [
    "In questo problema di classificazione sbilanciato quindi ci interessa massimizzare la recall.\\\n",
    "Infatti, una recall alta significa che c'è un basso numero di falsi negativi, cioè un basso numero di cattivi pagatori che il modello ha visto come buoni pagatori. In questo modo la banca si assicura di dare la carta solo a buoni pagatori.\\\n",
    "Inevitabilmente, massimizzando la recall si avrà una precision minore, cioè si avrà un alto numero di falsi positivi cioè di clienti che il modello ha visto come cattivi pagatori ma che in realtà sono buoni pagatori, quindi la banca su questo perderà dei potenziali buoni clienti ma si salvaguarderà dal rischio di cattivi pagatori."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc350b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0303080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/Vittorio D'Onofrio/Downloads/data.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d48e5",
   "metadata": {},
   "source": [
    "Intuitivamente, le variabili che indicano se un'osservazione ha o meno cellulare o una mail non sono indicative del fatto che quel cliente possa essere o meno un buon pagatore, quindi le eliminiamo dal dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c56093f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "900fe9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                         0\n",
       "CODE_GENDER                0\n",
       "FLAG_OWN_CAR               0\n",
       "FLAG_OWN_REALTY            0\n",
       "CNT_CHILDREN               0\n",
       "AMT_INCOME_TOTAL           0\n",
       "NAME_INCOME_TYPE           0\n",
       "NAME_EDUCATION_TYPE        0\n",
       "NAME_FAMILY_STATUS         0\n",
       "NAME_HOUSING_TYPE          0\n",
       "DAYS_BIRTH                 0\n",
       "DAYS_EMPLOYED              0\n",
       "OCCUPATION_TYPE        11323\n",
       "CNT_FAM_MEMBERS            0\n",
       "IS_BAD_PAYER               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2160a",
   "metadata": {},
   "source": [
    "Per il momento riempiamo i valori NaN della feature \"OCCUPATION_TYPE\" con una scritta indicante che manca il valore, ci occupiamo in seguito dell'encoding di questa feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a2668834",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['OCCUPATION_TYPE'] = data['OCCUPATION_TYPE'].fillna(\"valore assente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abf4f4",
   "metadata": {},
   "source": [
    "Procediamo con una one-hot encoding per la variabile indicante il sesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c5e86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies( data, columns=['CODE_GENDER' ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb437f38",
   "metadata": {},
   "source": [
    "Le features \"FLAG_OWN_CAR\" e \"FLAG_OWN_REALTY\" possono essere trasformate in numeriche con una codifica binaria mentre per la variabile \"NAME_EDUCATION_TYPE\" si può usare l'ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ecaad8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_realty_mapping={\n",
    "    \"Y\":1,\n",
    "    \"N\":0\n",
    "}\n",
    "\n",
    "education_mapping = {\n",
    "    \"Academic degree\": 5,\n",
    "    \"Higher education\": 4,\n",
    "    \"Incomplete higher\": 3,\n",
    "    \"Lower secondary\": 2,\n",
    "    \"Secondary / secondary special\": 1\n",
    "}\n",
    "\n",
    "\n",
    "data[\"FLAG_OWN_CAR\"]=data[\"FLAG_OWN_CAR\"].map(car_realty_mapping)\n",
    "data[\"FLAG_OWN_REALTY\"]=data[\"FLAG_OWN_REALTY\"].map(car_realty_mapping)\n",
    "data[\"NAME_EDUCATION_TYPE\"]=data[\"NAME_EDUCATION_TYPE\"].map(education_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f3a2d291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>IS_BAD_PAYER</th>\n",
       "      <th>CODE_GENDER_F</th>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5008804</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4275000</td>\n",
       "      <td>Working</td>\n",
       "      <td>4</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>valore assente</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5008805</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4275000</td>\n",
       "      <td>Working</td>\n",
       "      <td>4</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-12005</td>\n",
       "      <td>-4542</td>\n",
       "      <td>valore assente</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5008806</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1125000</td>\n",
       "      <td>Working</td>\n",
       "      <td>1</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-21474</td>\n",
       "      <td>-1134</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5008808</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2700000</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>1</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19110</td>\n",
       "      <td>-3051</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5008809</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2700000</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>1</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19110</td>\n",
       "      <td>-3051</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
       "0  5008804             1                1             0           4275000   \n",
       "1  5008805             1                1             0           4275000   \n",
       "2  5008806             1                1             0           1125000   \n",
       "3  5008808             0                1             0           2700000   \n",
       "4  5008809             0                1             0           2700000   \n",
       "\n",
       "       NAME_INCOME_TYPE  NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  \\\n",
       "0               Working                    4        Civil marriage   \n",
       "1               Working                    4        Civil marriage   \n",
       "2               Working                    1               Married   \n",
       "3  Commercial associate                    1  Single / not married   \n",
       "4  Commercial associate                    1  Single / not married   \n",
       "\n",
       "   NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED OCCUPATION_TYPE  \\\n",
       "0   Rented apartment      -12005          -4542  valore assente   \n",
       "1   Rented apartment      -12005          -4542  valore assente   \n",
       "2  House / apartment      -21474          -1134  Security staff   \n",
       "3  House / apartment      -19110          -3051     Sales staff   \n",
       "4  House / apartment      -19110          -3051     Sales staff   \n",
       "\n",
       "   CNT_FAM_MEMBERS  IS_BAD_PAYER  CODE_GENDER_F  CODE_GENDER_M  \n",
       "0               20             0              0              1  \n",
       "1               20             0              0              1  \n",
       "2               20             0              0              1  \n",
       "3               10             0              1              0  \n",
       "4               10             0              1              0  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e2546666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11272        1\n",
       "-4507         1\n",
       "-7698         1\n",
       "-4686         1\n",
       "-2160         1\n",
       "           ... \n",
       "-2087        61\n",
       "-200         63\n",
       "-1539        64\n",
       "-401         78\n",
       " 365243    6135\n",
       "Name: DAYS_EMPLOYED, Length: 3640, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DAYS_EMPLOYED'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f0573e",
   "metadata": {},
   "source": [
    "Abbiamo un solo valore positivo molto alto per la variabile 'DAYS_EMPLOYED', questo valore corrisponde ad un unico \"NAME_INCOME_TYPE\" cioè ai pensionati. Questo valore è chiaramente un outlier e potrebbe influenzare la capacità previsionale di un modello. Cambiamolo quindi con 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3a2eb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['DAYS_EMPLOYED'] > 0, 'DAYS_EMPLOYED'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae86a0f",
   "metadata": {},
   "source": [
    "Controlliamo se nelle features numeriche ci sono delle correlazioni lineari evidenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "61403d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>IS_BAD_PAYER</th>\n",
       "      <th>CODE_GENDER_F</th>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011163</td>\n",
       "      <td>-0.098851</td>\n",
       "      <td>0.028878</td>\n",
       "      <td>-0.017667</td>\n",
       "      <td>0.009211</td>\n",
       "      <td>0.056016</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>0.026624</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>-0.012022</td>\n",
       "      <td>0.012022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <td>-0.011163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015185</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.215506</td>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.157144</td>\n",
       "      <td>-0.006244</td>\n",
       "      <td>0.151814</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>-0.361379</td>\n",
       "      <td>0.361379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <td>-0.098851</td>\n",
       "      <td>-0.015185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>-0.010997</td>\n",
       "      <td>-0.129838</td>\n",
       "      <td>0.033646</td>\n",
       "      <td>-0.005723</td>\n",
       "      <td>-0.010987</td>\n",
       "      <td>0.050758</td>\n",
       "      <td>-0.050758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <td>0.028878</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033691</td>\n",
       "      <td>0.049823</td>\n",
       "      <td>0.339357</td>\n",
       "      <td>-0.043358</td>\n",
       "      <td>0.889114</td>\n",
       "      <td>-0.003710</td>\n",
       "      <td>-0.077690</td>\n",
       "      <td>0.077690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <td>-0.017667</td>\n",
       "      <td>0.215506</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>0.033691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.226931</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>-0.087130</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>-0.197805</td>\n",
       "      <td>0.197805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <td>0.009211</td>\n",
       "      <td>0.101272</td>\n",
       "      <td>-0.010997</td>\n",
       "      <td>0.049823</td>\n",
       "      <td>0.226931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169024</td>\n",
       "      <td>-0.016347</td>\n",
       "      <td>0.041344</td>\n",
       "      <td>0.010081</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>-0.005880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <td>0.056016</td>\n",
       "      <td>0.157144</td>\n",
       "      <td>-0.129838</td>\n",
       "      <td>0.339357</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>0.169024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023497</td>\n",
       "      <td>0.304020</td>\n",
       "      <td>-0.006954</td>\n",
       "      <td>-0.202352</td>\n",
       "      <td>0.202352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <td>0.005745</td>\n",
       "      <td>-0.006244</td>\n",
       "      <td>0.033646</td>\n",
       "      <td>-0.043358</td>\n",
       "      <td>-0.087130</td>\n",
       "      <td>-0.016347</td>\n",
       "      <td>-0.023497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054587</td>\n",
       "      <td>0.018482</td>\n",
       "      <td>-0.031731</td>\n",
       "      <td>0.031731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <td>0.026624</td>\n",
       "      <td>0.151814</td>\n",
       "      <td>-0.005723</td>\n",
       "      <td>0.889114</td>\n",
       "      <td>0.023750</td>\n",
       "      <td>0.041344</td>\n",
       "      <td>0.304020</td>\n",
       "      <td>-0.054587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005718</td>\n",
       "      <td>-0.110782</td>\n",
       "      <td>0.110782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS_BAD_PAYER</th>\n",
       "      <td>0.004892</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>-0.010987</td>\n",
       "      <td>-0.003710</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>0.010081</td>\n",
       "      <td>-0.006954</td>\n",
       "      <td>0.018482</td>\n",
       "      <td>-0.005718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014632</td>\n",
       "      <td>0.014632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CODE_GENDER_F</th>\n",
       "      <td>-0.012022</td>\n",
       "      <td>-0.361379</td>\n",
       "      <td>0.050758</td>\n",
       "      <td>-0.077690</td>\n",
       "      <td>-0.197805</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>-0.202352</td>\n",
       "      <td>-0.031731</td>\n",
       "      <td>-0.110782</td>\n",
       "      <td>-0.014632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "      <td>0.012022</td>\n",
       "      <td>0.361379</td>\n",
       "      <td>-0.050758</td>\n",
       "      <td>0.077690</td>\n",
       "      <td>0.197805</td>\n",
       "      <td>-0.005880</td>\n",
       "      <td>0.202352</td>\n",
       "      <td>0.031731</td>\n",
       "      <td>0.110782</td>\n",
       "      <td>0.014632</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ID  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "ID                   1.000000     -0.011163        -0.098851      0.028878   \n",
       "FLAG_OWN_CAR        -0.011163      1.000000        -0.015185      0.105839   \n",
       "FLAG_OWN_REALTY     -0.098851     -0.015185         1.000000     -0.000575   \n",
       "CNT_CHILDREN         0.028878      0.105839        -0.000575      1.000000   \n",
       "AMT_INCOME_TOTAL    -0.017667      0.215506         0.032719      0.033691   \n",
       "NAME_EDUCATION_TYPE  0.009211      0.101272        -0.010997      0.049823   \n",
       "DAYS_BIRTH           0.056016      0.157144        -0.129838      0.339357   \n",
       "DAYS_EMPLOYED        0.005745     -0.006244         0.033646     -0.043358   \n",
       "CNT_FAM_MEMBERS      0.026624      0.151814        -0.005723      0.889114   \n",
       "IS_BAD_PAYER         0.004892      0.001992        -0.010987     -0.003710   \n",
       "CODE_GENDER_F       -0.012022     -0.361379         0.050758     -0.077690   \n",
       "CODE_GENDER_M        0.012022      0.361379        -0.050758      0.077690   \n",
       "\n",
       "                     AMT_INCOME_TOTAL  NAME_EDUCATION_TYPE  DAYS_BIRTH  \\\n",
       "ID                          -0.017667             0.009211    0.056016   \n",
       "FLAG_OWN_CAR                 0.215506             0.101272    0.157144   \n",
       "FLAG_OWN_REALTY              0.032719            -0.010997   -0.129838   \n",
       "CNT_CHILDREN                 0.033691             0.049823    0.339357   \n",
       "AMT_INCOME_TOTAL             1.000000             0.226931    0.067908   \n",
       "NAME_EDUCATION_TYPE          0.226931             1.000000    0.169024   \n",
       "DAYS_BIRTH                   0.067908             0.169024    1.000000   \n",
       "DAYS_EMPLOYED               -0.087130            -0.016347   -0.023497   \n",
       "CNT_FAM_MEMBERS              0.023750             0.041344    0.304020   \n",
       "IS_BAD_PAYER                 0.007093             0.010081   -0.006954   \n",
       "CODE_GENDER_F               -0.197805             0.005880   -0.202352   \n",
       "CODE_GENDER_M                0.197805            -0.005880    0.202352   \n",
       "\n",
       "                     DAYS_EMPLOYED  CNT_FAM_MEMBERS  IS_BAD_PAYER  \\\n",
       "ID                        0.005745         0.026624      0.004892   \n",
       "FLAG_OWN_CAR             -0.006244         0.151814      0.001992   \n",
       "FLAG_OWN_REALTY           0.033646        -0.005723     -0.010987   \n",
       "CNT_CHILDREN             -0.043358         0.889114     -0.003710   \n",
       "AMT_INCOME_TOTAL         -0.087130         0.023750      0.007093   \n",
       "NAME_EDUCATION_TYPE      -0.016347         0.041344      0.010081   \n",
       "DAYS_BIRTH               -0.023497         0.304020     -0.006954   \n",
       "DAYS_EMPLOYED             1.000000        -0.054587      0.018482   \n",
       "CNT_FAM_MEMBERS          -0.054587         1.000000     -0.005718   \n",
       "IS_BAD_PAYER              0.018482        -0.005718      1.000000   \n",
       "CODE_GENDER_F            -0.031731        -0.110782     -0.014632   \n",
       "CODE_GENDER_M             0.031731         0.110782      0.014632   \n",
       "\n",
       "                     CODE_GENDER_F  CODE_GENDER_M  \n",
       "ID                       -0.012022       0.012022  \n",
       "FLAG_OWN_CAR             -0.361379       0.361379  \n",
       "FLAG_OWN_REALTY           0.050758      -0.050758  \n",
       "CNT_CHILDREN             -0.077690       0.077690  \n",
       "AMT_INCOME_TOTAL         -0.197805       0.197805  \n",
       "NAME_EDUCATION_TYPE       0.005880      -0.005880  \n",
       "DAYS_BIRTH               -0.202352       0.202352  \n",
       "DAYS_EMPLOYED            -0.031731       0.031731  \n",
       "CNT_FAM_MEMBERS          -0.110782       0.110782  \n",
       "IS_BAD_PAYER             -0.014632       0.014632  \n",
       "CODE_GENDER_F             1.000000      -1.000000  \n",
       "CODE_GENDER_M            -1.000000       1.000000  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde26a02",
   "metadata": {},
   "source": [
    "Come si può intuire, le features \"CNT_FAM_MEMBERS\" e \"CNT_CHILDREN\" sono altamente correlate, quindi possiamo scartare una delle due."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "701632c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['CNT_CHILDREN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad415a4",
   "metadata": {},
   "source": [
    "A questo punto restano quattro features di cui fare l'encoding. \\\n",
    "Si può pensare di fare una one-hot encoding per ogni variabile ma questo processo andrebbe ad aumentare di molto il numero delle features del dataset in modo forse non propriamente utile, perciò si può provare una frequency encoding, ovvero si può codificare ogni categoria di ogni variabile categorica con la frequenza del valore positivo della variabile target. Questo dovrebbe evidenziare (qualora ci fosse) la correlazione tra le features considerate e la variabile target. \\\n",
    "Con questo approccio si rischia però data leakage, ovvero se si fa la frequency encoding su tutto il dataset si darebbe al modello l'informazione sulla frequenza delle osservazioni del test anche in fase di training. \\\n",
    "Perciò si deve dividere il modello in train e test per completare questa fase di preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a554f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_encoding (X_train, X_test, Y_train, Y_test):\n",
    "\n",
    "    train, test = train_test_split ( data ,test_size=.3 , random_state=10)\n",
    "    \n",
    "    freq_occ = train.groupby('OCCUPATION_TYPE')['IS_BAD_PAYER'].sum()\n",
    "    freq_name = train.groupby('NAME_INCOME_TYPE')['IS_BAD_PAYER'].sum()\n",
    "    freq_fam = train.groupby('NAME_FAMILY_STATUS')['IS_BAD_PAYER'].sum()\n",
    "    freq_house = train.groupby('NAME_HOUSING_TYPE')['IS_BAD_PAYER'].sum()\n",
    "    \n",
    "    X_train = train.drop(\"IS_BAD_PAYER\", axis=1)\n",
    "    Y_train = train[\"IS_BAD_PAYER\"]\n",
    "    \n",
    "    X_test = test.drop(\"IS_BAD_PAYER\", axis=1)\n",
    "    Y_test = test[\"IS_BAD_PAYER\"]\n",
    "    \n",
    "    X_train['OCCUPATION_TYPE'] = X_train['OCCUPATION_TYPE'].map(freq_occ)\n",
    "    X_train['NAME_INCOME_TYPE'] = X_train['NAME_INCOME_TYPE'].map(freq_name)\n",
    "    X_train['NAME_FAMILY_STATUS'] = X_train['NAME_FAMILY_STATUS'].map(freq_fam)\n",
    "    X_train['NAME_HOUSING_TYPE'] = X_train['NAME_HOUSING_TYPE'].map(freq_house)\n",
    "    \n",
    "    X_test['OCCUPATION_TYPE'] = X_test['OCCUPATION_TYPE'].map(freq_occ)\n",
    "    X_test['NAME_INCOME_TYPE'] = X_test['NAME_INCOME_TYPE'].map(freq_name)\n",
    "    X_test['NAME_FAMILY_STATUS'] = X_test['NAME_FAMILY_STATUS'].map(freq_fam)\n",
    "    X_test['NAME_HOUSING_TYPE'] = X_test['NAME_HOUSING_TYPE'].map(freq_house)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68183863",
   "metadata": {},
   "source": [
    "Definiamo inoltre due funzioni di valutazione del modello, la funzione \"evaluate_model_proba\" in particolare sarà utile per regolare la soglia di probabilità di appartenenza alla classe positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d1692500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, subset):\n",
    "    X, y_true = dataset\n",
    "    y_pred = model.predict(X)\n",
    "    print(f\"METRICHE SUL {subset}:\\n \")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.3f}\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred):.3f}\")\n",
    "    print(f\"f1 score: {f1_score(y_true, y_pred):.3f}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.3f} \\n\")\n",
    "    print(f\"MATRICE DI CONFUSIONE: \\n {confusion_matrix(y_true, y_pred)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "10ff7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_proba(model, dataset, subset, threshold):\n",
    "    X, y_true = dataset\n",
    "    y_proba_pred = model.predict_proba(X)[:,1]\n",
    "    \n",
    "    binary_predictions = (y_proba_pred > threshold).astype(int)\n",
    "\n",
    "    print(f\"METRICHE SUL {subset}:\\n \")\n",
    "    print(f\"Precision: {precision_score(y_true, binary_predictions):.3f}\")\n",
    "    print(f\"Recall: {recall_score(y_true, binary_predictions):.3f}\")\n",
    "    print(f\"f1 score: {f1_score(y_true, binary_predictions):.3f}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, binary_predictions):.3f} \\n\")\n",
    "    print(f\"MATRICE DI CONFUSIONE: \\n {confusion_matrix(y_true, binary_predictions)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7c8ae",
   "metadata": {},
   "source": [
    "# Selezione del modello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57de7b4",
   "metadata": {},
   "source": [
    "Nella scelta del modello bisogna tenere presente che un punto chiave di questo problema è l'interpretabilità del risultato, cioè il modello deve anche riuscire a dare indicazioni su quali features abbiano pesato nella scelta della classe. \\\n",
    "Per questo motivo, scegliamo di non usare due metodi molto potenti come k-nn e reti neurali poichè l'interpretazione di questi modelli è molto difficile se non impossibile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4d415",
   "metadata": {},
   "source": [
    "Possiamo provare a vedere se è il caso di usare support vector machines, per questo andiamo a verificare se c'è una significativa presenza di outlier nel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c77bb8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonna: AMT_INCOME_TOTAL, numero di outliers: 1529\n",
      "Colonna: DAYS_BIRTH, numero di outliers: 0\n",
      "Colonna: DAYS_EMPLOYED, numero di outliers: 1770\n",
      "Colonna: CNT_FAM_MEMBERS, numero di outliers: 480\n"
     ]
    }
   ],
   "source": [
    "outlier_check = ['AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'CNT_FAM_MEMBERS']\n",
    "outliers = []\n",
    "\n",
    "for name_col in outlier_check:\n",
    "    Q1 = data[f'{name_col}'].quantile(0.25)\n",
    "    Q3 = data[f'{name_col}'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    outliers = data[(data[f'{name_col}'] < (Q1 - 1.5 * IQR)) | (data[f'{name_col}'] > (Q3 + 1.5 * IQR))]\n",
    "    \n",
    "    print (f'Colonna: {name_col}, numero di outliers: {outliers.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058ede4",
   "metadata": {},
   "source": [
    "In questo caso nel dataset ci sono molte osservazioni, non c'è una significativa presenza di outlier e quindi nemmeno i modelli support vector machines sembrano prestarsi bene a questo problema. Inoltre, i modelli svm non sono di facile interpretazione quando il kernel è diverso da quello lineare.\\\n",
    "Dunque, proviamo due modelli che hanno una buona interpretabilità: Logistic Regression e Naive Bayes. Infatti, con i coefficienti della regressione logistica, si può vedere quali features hanno pesato di più nella classificazione, mentre con Naive Bayes si può calcolare la probabilità di apparteneza ad una classe per una determinata osservazione e vedere quali sono le  features che hanno pesato di più come vedremo più avanti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5002762f",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a9954f",
   "metadata": {},
   "source": [
    "A priori, non ci si aspetta grandi risutati dalla regressione logistica dal momento che, come visto nella parte di preprocessing non c'è troppa correlazione lineare tra le variabili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c2fbce0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICHE SUL TRAIN:\n",
      " \n",
      "Precision: 0.008\n",
      "Recall: 0.632\n",
      "f1 score: 0.015\n",
      "Accuracy: 0.579 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[14687 10699]\n",
      " [   49    84]]\n",
      "METRICHE SUL TEST:\n",
      " \n",
      "Precision: 0.008\n",
      "Recall: 0.571\n",
      "f1 score: 0.015\n",
      "Accuracy: 0.569 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[6189 4686]\n",
      " [  27   36]]\n"
     ]
    }
   ],
   "source": [
    "Y = data[\"IS_BAD_PAYER\"].values\n",
    "X = data.drop(\"IS_BAD_PAYER\", axis=1).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split ( X,Y,test_size=.3 , random_state=10 )\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = freq_encoding(X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "evaluate_model(lr, (X_train, Y_train) , \"TRAIN\")\n",
    "\n",
    "evaluate_model(lr, (X_test, Y_test) , \"TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f5628",
   "metadata": {},
   "source": [
    "Come ci si poteva aspettare, la regressione logistica non è un buon modello predittivo in questo caso, scartiamo dunque questa strada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f672bd",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56a037",
   "metadata": {},
   "source": [
    "Per la scelta della probabilità a priori dell'algoritmo abbiamo due strade: si può scegliere di utilizzare la distribuzione Gaussiana in quanto le features \"AMT_INCOME_ANNUAL\", \"DAYS_BIRTH\" e \"DAYS_EMPLOYED\" sono continue oppure, visto che nella parte di preprocessing abbiamo scelto la frequency encoding, possiamo provare a trasformare le variabili continue in conteggi e usare quindi una distribuzione multinomiale oppure Complement Naive Bayes che dovrebbe essere più adatto a gestire lo sbilanciamento delle classi. Probabilmente con quest'ultimo approccio però si possono perdere informazioni sulle variabili continue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2628d00",
   "metadata": {},
   "source": [
    "Dal momento che Naive Bayes assume l'indipendenza tra le features, modifichiamo le colonne ottenute con la one hot encoding per la variabile indicante il sesso. Infatti le due features \"CODE_GENDER_F\" e \"CODE_GENDER_M\" saranno chiaramente dipendenti. In questo caso ci basta semplicemente rimuovere una delle due colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e75569e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['CODE_GENDER_F'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6d783",
   "metadata": {},
   "source": [
    "In più si può intuire che fissando due valori per \"DAYS_BIRTH\" e \"DAYS_EMPLOYED\" la colonna \"AMT_INCOME_TOTAL\" assume un unico valore. Proviamo a vedere se questa intuizione è fondata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "57035bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['combinazione'] = data['DAYS_BIRTH'].astype(str) + '_' + data['DAYS_EMPLOYED'].astype(str)\n",
    "\n",
    "count_amt = data.groupby('combinazione')['AMT_INCOME_TOTAL'].nunique()\n",
    "\n",
    "ones = count_amt[count_amt!=1]\n",
    "\n",
    "ones.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13209515",
   "metadata": {},
   "source": [
    "Per sole 182 osservazioni su più di 35000 del dataset si ha un valore non unico di \"AMT_INCOME_TOTAL\" una volta fissato \"DAYS_BIRTH\" e \"DAYS_EMPLOYED\". Perciò queste tre features non possono essere indipendenti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccabdbe3",
   "metadata": {},
   "source": [
    "Proviamo a scartare la variabile \"AMT_INCOME_TOTAL\" dal dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b1940463",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['AMT_INCOME_TOTAL', 'combinazione'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600c9a7",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ca843",
   "metadata": {},
   "source": [
    "Provo con l'undersampling a gestire lo sbilanciamento delle classi e fisso una soglia di 0.3 (che eventualmente è un parametro da migliorare), per aumentare la recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8aff8f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICHE SUL TRAIN:\n",
      " \n",
      "Precision: 0.521\n",
      "Recall: 0.925\n",
      "f1 score: 0.667\n",
      "Accuracy: 0.538 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[ 20 113]\n",
      " [ 10 123]]\n",
      "METRICHE SUL TEST:\n",
      " \n",
      "Precision: 0.006\n",
      "Recall: 0.921\n",
      "f1 score: 0.012\n",
      "Accuracy: 0.158 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[1675 9200]\n",
      " [   5   58]]\n"
     ]
    }
   ],
   "source": [
    "Y = data[\"IS_BAD_PAYER\"].values\n",
    "X = data.drop(\"IS_BAD_PAYER\", axis=1).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split ( X,Y,test_size=.3 , random_state=10 )\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = freq_encoding(X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "undersampler = RandomUnderSampler(sampling_strategy='auto' )\n",
    "\n",
    "X_train, Y_train = undersampler.fit_resample(X_train, Y_train)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "evaluate_model_proba(gnb, (X_train,Y_train), \"TRAIN\", 0.3)\n",
    "evaluate_model_proba(gnb, (X_test,Y_test), \"TEST\", 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6936343b",
   "metadata": {},
   "source": [
    "Proviamo a vedere se questo modello soffre di overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a9148bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metriche dopo 1 split di cross-validation: \n",
      "\n",
      "METRICHE SUL TRAIN:\n",
      " \n",
      "Precision: 0.519\n",
      "Recall: 0.932\n",
      "f1 score: 0.667\n",
      "Accuracy: 0.534 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[ 18 115]\n",
      " [  9 124]]\n",
      "METRICHE SUL TEST:\n",
      " \n",
      "Precision: 0.006\n",
      "Recall: 0.905\n",
      "f1 score: 0.012\n",
      "Accuracy: 0.146 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[1538 9337]\n",
      " [   6   57]]\n",
      "Metriche dopo 2 split di cross-validation: \n",
      "\n",
      "METRICHE SUL TRAIN:\n",
      " \n",
      "Precision: 0.534\n",
      "Recall: 0.940\n",
      "f1 score: 0.681\n",
      "Accuracy: 0.560 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[ 24 109]\n",
      " [  8 125]]\n",
      "METRICHE SUL TEST:\n",
      " \n",
      "Precision: 0.006\n",
      "Recall: 0.921\n",
      "f1 score: 0.012\n",
      "Accuracy: 0.144 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[1521 9354]\n",
      " [   5   58]]\n",
      "Metriche dopo 3 split di cross-validation: \n",
      "\n",
      "METRICHE SUL TRAIN:\n",
      " \n",
      "Precision: 0.515\n",
      "Recall: 0.925\n",
      "f1 score: 0.661\n",
      "Accuracy: 0.526 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[ 17 116]\n",
      " [ 10 123]]\n",
      "METRICHE SUL TEST:\n",
      " \n",
      "Precision: 0.007\n",
      "Recall: 0.952\n",
      "f1 score: 0.013\n",
      "Accuracy: 0.163 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[1719 9156]\n",
      " [   3   60]]\n",
      "Metriche dopo 4 split di cross-validation: \n",
      "\n",
      "METRICHE SUL TRAIN:\n",
      " \n",
      "Precision: 0.510\n",
      "Recall: 0.925\n",
      "f1 score: 0.658\n",
      "Accuracy: 0.519 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[ 15 118]\n",
      " [ 10 123]]\n",
      "METRICHE SUL TEST:\n",
      " \n",
      "Precision: 0.006\n",
      "Recall: 0.952\n",
      "f1 score: 0.013\n",
      "Accuracy: 0.150 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[1578 9297]\n",
      " [   3   60]]\n",
      "Metriche dopo 5 split di cross-validation: \n",
      "\n",
      "METRICHE SUL TRAIN:\n",
      " \n",
      "Precision: 0.512\n",
      "Recall: 0.940\n",
      "f1 score: 0.663\n",
      "Accuracy: 0.523 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[ 14 119]\n",
      " [  8 125]]\n",
      "METRICHE SUL TEST:\n",
      " \n",
      "Precision: 0.006\n",
      "Recall: 0.952\n",
      "f1 score: 0.013\n",
      "Accuracy: 0.141 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[1477 9398]\n",
      " [   3   60]]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle =True)\n",
    "i=1\n",
    "X = data.drop(\"IS_BAD_PAYER\", axis=1).values\n",
    "\n",
    "for train_index , test_index in kf.split(X):\n",
    "    \n",
    "    X_train , X_test = X[train_index] , X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = freq_encoding(X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "    undersampler = RandomUnderSampler(sampling_strategy='auto')\n",
    "    X_train, Y_train = undersampler.fit_resample(X_train, Y_train)\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, Y_train)\n",
    "    \n",
    "    print(f\"Metriche dopo {i} split di cross-validation: \\n\")\n",
    "    \n",
    "    evaluate_model_proba(gnb, (X_train,Y_train), \"TRAIN\", 0.3)\n",
    "    evaluate_model_proba(gnb, (X_test,Y_test), \"TEST\", 0.3)\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0d59b8",
   "metadata": {},
   "source": [
    "Il modello non sembra soffrire di overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36efbd34",
   "metadata": {},
   "source": [
    "### Interpretabilità"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d9d2a5",
   "metadata": {},
   "source": [
    "Tenendo presente che se y_pred è la classe predetta da Naive Bayes allora\n",
    "\n",
    "<center>\n",
    "    y_pred = argmax(P(y) * ∏ P(x_i | y))\n",
    "</center>\n",
    "\n",
    "e che P(y) è uguale per entrambe le classi visto che stiamo bilanciando il dataset con l'undersampling e che \n",
    "\n",
    "<center>\n",
    "    P(x_i | y) = (1 / (σ_y * sqrt(2 * π))) * exp(-(x_i - μ_y)^2 / (2 * σ_y^2))\n",
    "</center>\n",
    "\n",
    "si può osservare che più x_i è vicino alla media della feature i sulla classe y (μ_y) più l'esponenziale sarà vicino a 1 e quindi il valore P(x_i | y) sarà vicino al valore massimo.\\\n",
    "Perciò, supponiamo che l'osservazione x sia stata classificata come appartenente alla classe 1 cioè ∏ P(x_i | y=1) > ∏ P(x_i | y=0) (dimentichiamoci per un attimo del fatto che c'è una threshold). Fissato un i, se P(x_i | y=1) >> P(x_i | y=0) allora la feature i ha avuto un peso significativo nella scelta della classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9766d0",
   "metadata": {},
   "source": [
    "La seguente funzione \"probabilites\", data una osservazione x, individua per ogni i la differenza tra P(x_i | y=1) e P(x_i | y=0) in valore assoluto e restituisce tutte le features in ordine decrescente rispetto alla differenza in valore assoluto tra P(x_i | y=1) e P(x_i | y=0). Quindi le prime features dell'output saranno quelle più influenti nella scelta della classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "48f1a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities (x):\n",
    "    positive_class = []\n",
    "    negative_class = []\n",
    "    \n",
    "    prob_pos = 1\n",
    "    prob_neg = 1\n",
    "    \n",
    "    difference = []\n",
    "    difference_norm = []\n",
    "    \n",
    "    list_index = []\n",
    "    \n",
    "    for feature_index in range(X_train.shape[1]):\n",
    "        mean_neg = gnb.theta_[0, feature_index]\n",
    "        mean_pos = gnb.theta_[1, feature_index]\n",
    "    \n",
    "        std_dev_neg = np.sqrt(gnb.var_[0, feature_index])\n",
    "        std_dev_pos = np.sqrt(gnb.var_[1, feature_index])\n",
    "        \n",
    "        conditional_prob_pos = (1 / (np.sqrt(2 * np.pi) * std_dev_pos)) * np.exp(-(x[feature_index] - mean_pos) ** 2 / (2 * std_dev_pos ** 2))\n",
    "        conditional_prob_neg = (1 / (np.sqrt(2 * np.pi) * std_dev_neg)) * np.exp(-(x[feature_index] - mean_neg) ** 2 / (2 * std_dev_neg ** 2))\n",
    "        \n",
    "        \n",
    "        positive_class.append(conditional_prob_pos)\n",
    "        negative_class.append(conditional_prob_neg)\n",
    "        \n",
    "    for val in positive_class:\n",
    "        prob_pos*=val\n",
    "    \n",
    "    for val_n in negative_class:\n",
    "        prob_neg*=val_n\n",
    "        \n",
    "    norm_pos = prob_pos / (prob_pos+prob_neg)\n",
    "    norm_neg = prob_neg / (prob_pos+prob_neg)\n",
    "    \n",
    "    pred_class = (1 if norm_pos > norm_neg or norm_pos >= 0.3 else 0)  #threshold=0.3\n",
    "    \n",
    "    print(f\"Probabilità che sia un cattivo pagatore: {norm_pos:.2f}\")\n",
    "    print(f\"Probabilità che sia un buon pagatore: {norm_neg:.2f}\\n\")\n",
    "    print(f\"Classe predetta: {pred_class} \\n\")\n",
    "    for elem1, elem2 in zip(positive_class, negative_class):\n",
    "        difference.append(abs(elem1 - elem2))\n",
    "    \n",
    "    for i in range(len(difference)):\n",
    "        \n",
    "        index = difference.index(max(difference))\n",
    "        list_index.append(index)\n",
    "        difference[index] = 0\n",
    "    \n",
    "    print(\"Features ordinate per importanza nella scelta della classe: \\n \")\n",
    "    \n",
    "    for j in list_index:\n",
    "        print(f\"{X_train.columns[j]} \")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "998e7a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.predict_proba(X_train)[:,1]>0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae328f9",
   "metadata": {},
   "source": [
    "La prima osservazione del train ad esempio è stata classificata come cattivo pagatore, vediamo quali sono state le features che hanno influito di più nella scelta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "05df84ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilità che sia un cattivo pagatore: 0.45\n",
      "Probabilità che sia un buon pagatore: 0.55\n",
      "\n",
      "Classe predetta: 1 \n",
      "\n",
      "Features ordinate per importanza nella scelta della classe: \n",
      " \n",
      "NAME_EDUCATION_TYPE \n",
      "CODE_GENDER_M \n",
      "FLAG_OWN_REALTY \n",
      "CNT_FAM_MEMBERS \n",
      "NAME_FAMILY_STATUS \n",
      "NAME_INCOME_TYPE \n",
      "OCCUPATION_TYPE \n",
      "NAME_HOUSING_TYPE \n",
      "DAYS_EMPLOYED \n",
      "DAYS_BIRTH \n",
      "ID \n",
      "ID \n"
     ]
    }
   ],
   "source": [
    "probabilities(X_train.iloc[0].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc544f47",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a45a0",
   "metadata": {},
   "source": [
    "Proviamo ora ad utilizzare una probabilità a priori diversa da quella Gaussiana. Per poter usare Multinomial Naive Bayes oppure Complement Naive Bayes che in teoria è anche adatto a gestire lo sbilanciamento delle classi, bisogna fare qualche modifica alle variabili continue del dataset per renderle discrete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63e726a",
   "metadata": {},
   "source": [
    "Proviamo a dividere le features continue utilizzando i quantili e quindi dividendole in quattro intervalli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f2b1c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_features(col):\n",
    "    \n",
    "    quantili = data[f'{col}'].quantile([0, 0.25, 0.5, 0.75, 1])\n",
    "\n",
    "    intervalli = [float('-inf'), quantili[0.25], quantili[0.5], quantili[0.75], float('inf')]\n",
    "\n",
    "    etichette = [1, 2, 3, 4]\n",
    "\n",
    "\n",
    "    data[f'{col}'] = pd.cut(data[f'{col}'], bins=intervalli, labels=etichette)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4c14ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#disc_features('AMT_INCOME_TOTAL')\n",
    "disc_features('DAYS_BIRTH')\n",
    "disc_features('DAYS_EMPLOYED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "851eb064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICHE SUL TRAIN:\n",
      " \n",
      "Precision: 0.528\n",
      "Recall: 0.714\n",
      "f1 score: 0.607\n",
      "Accuracy: 0.538 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[48 85]\n",
      " [38 95]]\n",
      "METRICHE SUL TEST:\n",
      " \n",
      "Precision: 0.006\n",
      "Recall: 0.683\n",
      "f1 score: 0.011\n",
      "Accuracy: 0.309 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[3333 7542]\n",
      " [  20   43]]\n"
     ]
    }
   ],
   "source": [
    "Y = data[\"IS_BAD_PAYER\"].values\n",
    "X = data.drop(\"IS_BAD_PAYER\", axis=1).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split ( X,Y,test_size=.3 , random_state=10 )\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = freq_encoding(X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "undersampler = RandomUnderSampler(sampling_strategy='auto')\n",
    "X_train, Y_train = undersampler.fit_resample(X_train, Y_train)\n",
    "\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, Y_train)\n",
    "\n",
    "evaluate_model_proba(mnb, (X_train,Y_train), \"TRAIN\", 0.3)\n",
    "evaluate_model_proba(mnb, (X_test,Y_test), \"TEST\", 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c953d630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICHE SUL TRAIN:\n",
      " \n",
      "Precision: 0.594\n",
      "Recall: 0.780\n",
      "f1 score: 0.674\n",
      "Accuracy: 0.623 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[11832 13554]\n",
      " [ 5590 19796]]\n",
      "METRICHE SUL TEST:\n",
      " \n",
      "Precision: 0.006\n",
      "Recall: 0.571\n",
      "f1 score: 0.012\n",
      "Accuracy: 0.475 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[5162 5713]\n",
      " [  27   36]]\n"
     ]
    }
   ],
   "source": [
    "Y = data[\"IS_BAD_PAYER\"].values\n",
    "X = data.drop(\"IS_BAD_PAYER\", axis=1).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split ( X,Y,test_size=.3 , random_state=10 )\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = freq_encoding(X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, Y_train = smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, Y_train)\n",
    "\n",
    "evaluate_model_proba(mnb, (X_train,Y_train), \"TRAIN\", 0.3)\n",
    "evaluate_model_proba(mnb, (X_test,Y_test), \"TEST\", 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f7a7a",
   "metadata": {},
   "source": [
    "L'approccio scelto con Multinomial Naive Bayes non produce un buon modello, nè con oversampliing nè con undersampling, questo perchè probabilmente nella trasformazione delle variabili continue in discrete sono state perse informazioni preziose per la classificazione. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3688ae8",
   "metadata": {},
   "source": [
    "## Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7a5ab383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICHE SUL TRAIN:\n",
      " \n",
      "Precision: 0.006\n",
      "Recall: 0.812\n",
      "f1 score: 0.012\n",
      "Accuracy: 0.308 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[ 7743 17643]\n",
      " [   25   108]]\n",
      "METRICHE SUL TEST:\n",
      " \n",
      "Precision: 0.007\n",
      "Recall: 0.794\n",
      "f1 score: 0.013\n",
      "Accuracy: 0.318 \n",
      "\n",
      "MATRICE DI CONFUSIONE: \n",
      " [[3429 7446]\n",
      " [  13   50]]\n"
     ]
    }
   ],
   "source": [
    "Y = data[\"IS_BAD_PAYER\"].values\n",
    "X = data.drop(\"IS_BAD_PAYER\", axis=1).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split ( X,Y,test_size=.3 , random_state=10 )\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = freq_encoding(X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train, Y_train)\n",
    "\n",
    "evaluate_model_proba(cnb, (X_train,Y_train), \"TRAIN\", 0.3)\n",
    "evaluate_model_proba(cnb, (X_test,Y_test), \"TEST\", 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e44ce4",
   "metadata": {},
   "source": [
    "Complement Naive Bayes produce un modello che ha una buona recall anche senza bilanciare le classi ma comunque funziona peggio rispetto a Gaussian NB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0ee0a",
   "metadata": {},
   "source": [
    "## Conclusioni "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311e8ed",
   "metadata": {},
   "source": [
    "In definitiva, il modello Gaussian Naive Bayes sembra essere il modello più adatto al caso di business tra quelli considerati perchè produce una buona recall e ha una buona interpretabilità."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
